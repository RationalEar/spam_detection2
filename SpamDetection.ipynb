{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a84d16cb",
      "metadata": {
        "id": "a84d16cb",
        "outputId": "2b2049e4-34c0-438d-b183-58016dcf0829"
      },
      "source": [
        "#### Google Colab: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "09bd9021",
      "metadata": {
        "id": "09bd9021",
        "outputId": "e0aa7415-36b6-4981-db1e-d5462154d55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 1.10 KiB | 1.10 MiB/s, done.\n",
            "From https://github.com/RationalEar/spam_detection2\n",
            "   413e8a7..bb7f178  master     -> origin/master\n",
            "Updating 413e8a7..bb7f178\n",
            "Fast-forward\n",
            " train.py | 13 \u001b[32m++++++++++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 10 insertions(+), 3 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "# clone the repository if directory `/content/spam_detection2` does not exist and we're not already in it\n",
        "import os\n",
        "\n",
        "workspace_dir = '/content/spam_detection2'\n",
        "current_dir = os.getcwd()\n",
        "if not os.path.exists(workspace_dir) and current_dir != workspace_dir:\n",
        "    !git clone https://github.com/RationalEar/spam_detection2.git\n",
        "    os.chdir(workspace_dir)\n",
        "    !ls -al\n",
        "    !pip install -q transformers==4.48.0 scikit-learn pandas numpy matplotlib mlflow beautifulsoup4 shap lime\n",
        "    !pip install -q torch --index-url https://download.pytorch.org/whl/cu126\n",
        "else:\n",
        "    os.chdir(workspace_dir)\n",
        "    !git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "be127122",
      "metadata": {
        "id": "be127122"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from utils.preprocessor import load_glove_embeddings\n",
        "from train import train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "540f2cac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "540f2cac",
        "outputId": "a58b7eac-2b4d-42c3-cc8c-37029daaedf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for saving models\n",
        "drive.mount('/content/drive')\n",
        "ROOT_PATH = '/content/drive/MyDrive/Projects/spam_detection2/'\n",
        "MODEL_SAVE_PATH = os.path.join(ROOT_PATH, 'models')\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fd6ed652",
      "metadata": {
        "id": "fd6ed652"
      },
      "outputs": [],
      "source": [
        "from train import set_seed\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "975fb231",
      "metadata": {
        "id": "975fb231"
      },
      "source": [
        "#### Load preprocessed data (assumes PKLs/CSVs are available in data/processed/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9df1afdf",
      "metadata": {
        "id": "9df1afdf"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_pickle(ROOT_PATH + 'data/processed/train.pkl')\n",
        "test_df = pd.read_pickle(ROOT_PATH + 'data/processed/test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6882dd41",
      "metadata": {
        "id": "6882dd41"
      },
      "outputs": [],
      "source": [
        "# Build vocabulary from training data\n",
        "from utils.functions import build_vocab\n",
        "\n",
        "word2idx = build_vocab(train_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e2e70a7d",
      "metadata": {
        "id": "e2e70a7d"
      },
      "outputs": [],
      "source": [
        "# Load GloVe embeddings\n",
        "GLOVE_PATH = os.path.join(ROOT_PATH, 'data/raw/glove.6B/glove.6B.300d.txt')\n",
        "embedding_dim = 300\n",
        "max_len = 200\n",
        "pretrained_embeddings = load_glove_embeddings(GLOVE_PATH, word2idx, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90bc2296",
      "metadata": {
        "id": "90bc2296"
      },
      "source": [
        "#### Train CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7df22ca6",
      "metadata": {
        "id": "7df22ca6",
        "outputId": "2e5be65f-9da1-45d6-8f29-3b72693fc1f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Loss: 0.3674\n",
            "Epoch 2/50 - Loss: 0.1603\n",
            "Epoch 3/50 - Loss: 0.1075\n",
            "Epoch 4/50 - Loss: 0.0653\n",
            "Epoch 5/50 - Loss: 0.0533\n",
            "Epoch 6/50 - Loss: 0.0426\n",
            "Epoch 7/50 - Loss: 0.0336\n",
            "Epoch 8/50 - Loss: 0.0319\n",
            "Epoch 9/50 - Loss: 0.0288\n",
            "Epoch 10/50 - Loss: 0.0261\n",
            "Epoch 11/50 - Loss: 0.0215\n",
            "Epoch 12/50 - Loss: 0.0272\n",
            "Epoch 13/50 - Loss: 0.0143\n",
            "Epoch 14/50 - Loss: 0.0193\n",
            "Epoch 15/50 - Loss: 0.0170\n",
            "Epoch 16/50 - Loss: 0.0135\n",
            "Epoch 17/50 - Loss: 0.0126\n",
            "Epoch 18/50 - Loss: 0.0125\n",
            "Epoch 19/50 - Loss: 0.0115\n",
            "Epoch 20/50 - Loss: 0.0308\n",
            "Epoch 21/50 - Loss: 0.0318\n",
            "Epoch 22/50 - Loss: 0.0212\n",
            "Epoch 23/50 - Loss: 0.0184\n",
            "Epoch 24/50 - Loss: 0.0137\n",
            "Epoch 25/50 - Loss: 0.0169\n",
            "Epoch 26/50 - Loss: 0.0134\n",
            "Epoch 27/50 - Loss: 0.0114\n",
            "Epoch 28/50 - Loss: 0.0107\n",
            "Epoch 29/50 - Loss: 0.0104\n",
            "Epoch 30/50 - Loss: 0.0105\n",
            "Epoch 31/50 - Loss: 0.0099\n",
            "Epoch 32/50 - Loss: 0.0101\n",
            "Epoch 33/50 - Loss: 0.0102\n",
            "Epoch 34/50 - Loss: 0.0114\n",
            "Epoch 35/50 - Loss: 0.0102\n",
            "Epoch 36/50 - Loss: 0.0105\n",
            "Epoch 37/50 - Loss: 0.0104\n",
            "Epoch 38/50 - Loss: 0.0107\n",
            "Epoch 39/50 - Loss: 0.0103\n",
            "Epoch 40/50 - Loss: 0.0105\n",
            "Epoch 41/50 - Loss: 0.0108\n",
            "Epoch 42/50 - Loss: 0.0103\n",
            "Epoch 43/50 - Loss: 0.0107\n",
            "Epoch 44/50 - Loss: 0.0100\n",
            "Epoch 45/50 - Loss: 0.0103\n",
            "Epoch 46/50 - Loss: 0.0100\n",
            "Epoch 47/50 - Loss: 0.0128\n",
            "Epoch 48/50 - Loss: 0.0749\n",
            "Epoch 49/50 - Loss: 0.0301\n",
            "Epoch 50/50 - Loss: 0.0155\n",
            "Model saved to /content/drive/MyDrive/Projects/spam_detection2/models/spam_cnn.pt\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.93      0.96       830\n",
            "         1.0       0.87      0.97      0.92       380\n",
            "\n",
            "    accuracy                           0.95      1210\n",
            "   macro avg       0.93      0.95      0.94      1210\n",
            "weighted avg       0.95      0.95      0.95      1210\n",
            "\n",
            "Confusion Matrix:\n",
            " [[776  54]\n",
            " [ 12 368]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpamCNN(\n",
              "  (embedding): Embedding(25373, 300)\n",
              "  (conv1): Conv1d(300, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (conv2): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "  (conv3): Conv1d(64, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "  (global_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
              "  (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_model('cnn', train_df, test_df, embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings,\n",
        "                model_save_path=MODEL_SAVE_PATH, max_len=max_len, evaluate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffd5c9e",
      "metadata": {
        "id": "6ffd5c9e",
        "outputId": "955a3038-aa2c-4163-def5-8b15e5c21859"
      },
      "source": [
        "#### Train BiLSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7424b1a7",
      "metadata": {
        "id": "7424b1a7",
        "outputId": "b8b54e09-a0ad-4e41-dfca-567941dc3042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 - Loss: 0.5182\n",
            "Epoch 2/40 - Loss: 0.2423\n",
            "Epoch 3/40 - Loss: 0.1502\n",
            "Epoch 4/40 - Loss: 0.1268\n",
            "Epoch 5/40 - Loss: 0.1012\n",
            "Epoch 6/40 - Loss: 0.0966\n",
            "Epoch 7/40 - Loss: 0.0852\n",
            "Epoch 8/40 - Loss: 0.0670\n",
            "Epoch 9/40 - Loss: 0.0706\n",
            "Epoch 10/40 - Loss: 0.0589\n",
            "Epoch 11/40 - Loss: 0.0512\n",
            "Epoch 12/40 - Loss: 0.0377\n",
            "Epoch 13/40 - Loss: 0.0344\n",
            "Epoch 14/40 - Loss: 0.0263\n",
            "Epoch 15/40 - Loss: 0.0255\n",
            "Epoch 16/40 - Loss: 0.0305\n",
            "Epoch 17/40 - Loss: 0.0292\n",
            "Epoch 18/40 - Loss: 0.0271\n",
            "Epoch 19/40 - Loss: 0.0189\n",
            "Epoch 20/40 - Loss: 0.0122\n",
            "Epoch 21/40 - Loss: 0.0195\n",
            "Epoch 22/40 - Loss: 0.0203\n",
            "Epoch 23/40 - Loss: 0.0155\n",
            "Epoch 24/40 - Loss: 0.0138\n",
            "Epoch 25/40 - Loss: 0.0171\n",
            "Epoch 26/40 - Loss: 0.0122\n",
            "Epoch 27/40 - Loss: 0.0109\n",
            "Epoch 28/40 - Loss: 0.0107\n",
            "Epoch 29/40 - Loss: 0.0102\n",
            "Epoch 30/40 - Loss: 0.0104\n",
            "Epoch 31/40 - Loss: 0.0106\n",
            "Epoch 32/40 - Loss: 0.0106\n",
            "Epoch 33/40 - Loss: 0.0105\n",
            "Epoch 34/40 - Loss: 0.0101\n",
            "Epoch 35/40 - Loss: 0.0107\n",
            "Epoch 36/40 - Loss: 0.0101\n",
            "Epoch 37/40 - Loss: 0.0104\n",
            "Epoch 38/40 - Loss: 0.0107\n",
            "Epoch 39/40 - Loss: 0.0108\n",
            "Epoch 40/40 - Loss: 0.0109\n",
            "Model saved to /content/drive/MyDrive/Projects/spam_detection2/models/spam_bilstm.pt\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.97      0.98       830\n",
            "         1.0       0.95      0.96      0.95       380\n",
            "\n",
            "    accuracy                           0.97      1210\n",
            "   macro avg       0.96      0.97      0.96      1210\n",
            "weighted avg       0.97      0.97      0.97      1210\n",
            "\n",
            "Confusion Matrix:\n",
            " [[809  21]\n",
            " [ 16 364]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTMSpam(\n",
              "  (embedding): Embedding(25373, 300)\n",
              "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (attention): Attention(\n",
              "    (attn): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_model('bilstm', train_df, test_df, embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings,\n",
        "                model_save_path=MODEL_SAVE_PATH, max_len=max_len, evaluate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56b709c",
      "metadata": {
        "id": "f56b709c"
      },
      "source": [
        "#### Train BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1d27ec27",
      "metadata": {
        "id": "1d27ec27",
        "outputId": "39d4bded-0899-4698-c575-596488dfa6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.1961\n",
            "Epoch 2/10 - Loss: 0.0694\n",
            "Epoch 3/10 - Loss: 0.0415\n",
            "Epoch 4/10 - Loss: 0.0269\n",
            "Epoch 5/10 - Loss: 0.0239\n",
            "Epoch 6/10 - Loss: 0.0220\n",
            "Epoch 7/10 - Loss: 0.0179\n",
            "Epoch 8/10 - Loss: 0.0147\n",
            "Epoch 9/10 - Loss: 0.0117\n",
            "Epoch 10/10 - Loss: 0.0115\n",
            "Model saved to /content/drive/MyDrive/Projects/spam_detection2/models/spam_bert.pt\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.98      0.98       830\n",
            "         1.0       0.95      0.98      0.97       380\n",
            "\n",
            "    accuracy                           0.98      1210\n",
            "   macro avg       0.97      0.98      0.97      1210\n",
            "weighted avg       0.98      0.98      0.98      1210\n",
            "\n",
            "Confusion Matrix:\n",
            " [[810  20]\n",
            " [  7 373]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpamBERT(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_model('bert', train_df, test_df, embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings,\n",
        "                model_save_path=MODEL_SAVE_PATH, max_len=max_len, evaluate=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}