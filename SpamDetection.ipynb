{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a84d16cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a84d16cb",
        "outputId": "2b2049e4-34c0-438d-b183-58016dcf0829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spam_detection2'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 22 (delta 3), reused 22 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (22/22), 39.61 KiB | 19.80 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RationalEar/spam_detection2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0ff664a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ff664a2",
        "outputId": "55664cd9-5776-4260-91b8-7715bb7200e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 196\n",
            "drwxr-xr-x 6 root root   4096 May  3 14:06 .\n",
            "drwxr-xr-x 1 root root   4096 May  3 14:06 ..\n",
            "-rw-r--r-- 1 root root    637 May  3 14:06 changelog.md\n",
            "drwxr-xr-x 8 root root   4096 May  3 14:06 .git\n",
            "drwxr-xr-x 2 root root   4096 May  3 14:06 .github\n",
            "-rw-r--r-- 1 root root     61 May  3 14:06 .gitignore\n",
            "-rw-r--r-- 1 root root   5754 May  3 14:06 implementation-plan.md\n",
            "-rw-r--r-- 1 root root   1015 May  3 14:06 local.ipynb\n",
            "drwxr-xr-x 2 root root   4096 May  3 14:06 models\n",
            "-rw-r--r-- 1 root root   1754 May  3 14:06 requirements.txt\n",
            "-rw-r--r-- 1 root root   9128 May  3 14:06 SpamDetection.ipynb\n",
            "-rw-r--r-- 1 root root 136084 May  3 14:06 thesis.md\n",
            "drwxr-xr-x 2 root root   4096 May  3 14:06 utils\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/spam_detection2')\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f3d7e967",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3d7e967",
        "outputId": "b74ec239-63d5-4be5-f4d0-a3614522e73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Google Colab: Environment Setup\n",
        "!pip install -q transformers==4.48.0 scikit-learn pandas numpy matplotlib mlflow beautifulsoup4 shap lime\n",
        "!pip install -q torch --index-url https://download.pytorch.org/whl/cu126"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "be127122",
      "metadata": {
        "id": "be127122"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils.preprocessor import preprocess_text, load_glove_embeddings\n",
        "from models.cnn import SpamCNN\n",
        "from models.bilstm import BiLSTMSpam\n",
        "from models.bert import SpamBERT\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "540f2cac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "540f2cac",
        "outputId": "beae2425-b0ce-4321-a98a-7da7daab4650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for saving models\n",
        "drive.mount('/content/drive')\n",
        "ROOT_PATH = '/content/drive/MyDrive/Projects/spam_detection2/'\n",
        "MODEL_SAVE_PATH = os.path.join(ROOT_PATH, 'models')\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fd6ed652",
      "metadata": {
        "id": "fd6ed652"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "975fb231",
      "metadata": {
        "id": "975fb231"
      },
      "outputs": [],
      "source": [
        "# Load preprocessed data (assumes PKLs/CSVs are available in data/processed/)\n",
        "train_df = pd.read_pickle(ROOT_PATH + 'data/processed/train.pkl')\n",
        "test_df = pd.read_pickle(ROOT_PATH + 'data/processed/test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6882dd41",
      "metadata": {
        "id": "6882dd41"
      },
      "outputs": [],
      "source": [
        "# Build vocabulary from training data\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    from collections import Counter\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(text.split())\n",
        "    vocab = {word for word, freq in counter.items() if freq >= min_freq}\n",
        "    word2idx = {word: idx+2 for idx, word in enumerate(sorted(vocab))}\n",
        "    word2idx['<PAD>'] = 0\n",
        "    word2idx['<UNK>'] = 1\n",
        "    return word2idx\n",
        "\n",
        "word2idx = build_vocab(train_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6ae2e18a",
      "metadata": {
        "id": "6ae2e18a"
      },
      "outputs": [],
      "source": [
        "# Tokenize and numericalize\n",
        "max_len = 200\n",
        "def encode(text, word2idx, max_len=200):\n",
        "    tokens = text.split()\n",
        "    idxs = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
        "    if len(idxs) < max_len:\n",
        "        idxs += [word2idx['<PAD>']] * (max_len - len(idxs))\n",
        "    else:\n",
        "        idxs = idxs[:max_len]\n",
        "    return idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5879716c",
      "metadata": {
        "id": "5879716c"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor([encode(t, word2idx, max_len) for t in train_df['text']])\n",
        "y_train = torch.tensor(train_df['label'].values, dtype=torch.float32)\n",
        "X_test = torch.tensor([encode(t, word2idx, max_len) for t in test_df['text']])\n",
        "y_test = torch.tensor(test_df['label'].values, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e2e70a7d",
      "metadata": {
        "id": "e2e70a7d"
      },
      "outputs": [],
      "source": [
        "# Load GloVe embeddings\n",
        "GLOVE_PATH = os.path.join(ROOT_PATH, 'data/raw/glove.6B/glove.6B.300d.txt')\n",
        "embedding_dim = 300\n",
        "pretrained_embeddings = load_glove_embeddings(GLOVE_PATH, word2idx, embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "90bc2296",
      "metadata": {
        "id": "90bc2296"
      },
      "outputs": [],
      "source": [
        "# Choose model: 'cnn', 'bilstm', or 'bert'\n",
        "model_type = 'bert'  # Change to 'bilstm' or 'bert' as needed\n",
        "\n",
        "if model_type == 'cnn':\n",
        "    model = SpamCNN(vocab_size=len(word2idx), embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings)\n",
        "    train_inputs, train_labels = X_train, y_train\n",
        "    test_inputs, test_labels = X_test, y_test\n",
        "elif model_type == 'bilstm':\n",
        "    model = BiLSTMSpam(vocab_size=len(word2idx), embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings)\n",
        "    train_inputs, train_labels = X_train, y_train\n",
        "    test_inputs, test_labels = X_test, y_test\n",
        "elif model_type == 'bert':\n",
        "    from transformers import BertTokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    def bert_encode(texts, tokenizer, max_len=200):\n",
        "        return tokenizer(texts.tolist(), padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')\n",
        "    train_encodings = bert_encode(train_df['text'], tokenizer, max_len)\n",
        "    test_encodings = bert_encode(test_df['text'], tokenizer, max_len)\n",
        "    model = SpamBERT()\n",
        "    train_inputs, train_labels = train_encodings, y_train\n",
        "    test_inputs, test_labels = test_encodings, y_test\n",
        "else:\n",
        "    raise ValueError('Invalid model_type')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6ffd5c9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ffd5c9e",
        "outputId": "955a3038-aa2c-4163-def5-8b15e5c21859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.2237\n",
            "Epoch 2/10 - Loss: 0.2631\n",
            "Epoch 3/10 - Loss: 0.6303\n",
            "Epoch 4/10 - Loss: 0.6259\n",
            "Epoch 5/10 - Loss: 0.6305\n",
            "Epoch 6/10 - Loss: 0.6299\n",
            "Epoch 7/10 - Loss: 0.6259\n",
            "Epoch 8/10 - Loss: 0.6270\n",
            "Epoch 9/10 - Loss: 0.6285\n",
            "Epoch 10/10 - Loss: 0.6328\n",
            "Model saved to /content/drive/MyDrive/Projects/spam_detection2/models/spam_bert.pt\n"
          ]
        }
      ],
      "source": [
        "# Move model to GPU if available\n",
        "model = model.cuda() if torch.cuda.is_available() else model\n",
        "\n",
        "# Training Loop\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-4)\n",
        "\n",
        "if model_type in ['cnn', 'bilstm']:\n",
        "    train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "    test_dataset = TensorDataset(test_inputs, test_labels)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "else:  # BERT\n",
        "    train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "    test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        if model_type == 'bert':\n",
        "            input_ids, attention_mask, labels = [b.cuda() if torch.cuda.is_available() else b for b in batch]\n",
        "            outputs, _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        else:\n",
        "            inputs, labels = [b.cuda() if torch.cuda.is_available() else b for b in batch]\n",
        "            outputs = model(inputs)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Save model to Google Drive\n",
        "model_save_file = os.path.join(MODEL_SAVE_PATH, f'spam_{model_type}.pt')\n",
        "model.save(model_save_file)\n",
        "print(f\"Model saved to {model_save_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f647f947",
      "metadata": {
        "id": "f647f947"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}