{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab: Environment Setup\n",
    "!pip install -q transformers==4.48.0 scikit-learn pandas numpy matplotlib mlflow beautifulsoup4 shap lime\n",
    "!pip install -q torch --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be127122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.preprocessor import preprocess_text, load_glove_embeddings\n",
    "from models.cnn import SpamCNN\n",
    "from models.bilstm import BiLSTMSpam\n",
    "from models.bert import SpamBERT\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for saving models\n",
    "drive.mount('/content/drive')\n",
    "ROOT_PATH = '/content/drive/MyDrive/Projects/spam_detection2/'\n",
    "MODEL_SAVE_PATH = os.path.join(ROOT_PATH, 'models')\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ed652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data (assumes CSVs are available in data/processed/)\n",
    "train_df = pd.read_csv('data/processed/train.csv')\n",
    "test_df = pd.read_csv('data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from training data\n",
    "def build_vocab(texts, min_freq=2):\n",
    "    from collections import Counter\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(text.split())\n",
    "    vocab = {word for word, freq in counter.items() if freq >= min_freq}\n",
    "    word2idx = {word: idx+2 for idx, word in enumerate(sorted(vocab))}\n",
    "    word2idx['<PAD>'] = 0\n",
    "    word2idx['<UNK>'] = 1\n",
    "    return word2idx\n",
    "\n",
    "word2idx = build_vocab(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and numericalize\n",
    "max_len = 200\n",
    "def encode(text, word2idx, max_len=200):\n",
    "    tokens = text.split()\n",
    "    idxs = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "    if len(idxs) < max_len:\n",
    "        idxs += [word2idx['<PAD>']] * (max_len - len(idxs))\n",
    "    else:\n",
    "        idxs = idxs[:max_len]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([encode(t, word2idx, max_len) for t in train_df['text']])\n",
    "y_train = torch.tensor(train_df['label'].values, dtype=torch.float32)\n",
    "X_test = torch.tensor([encode(t, word2idx, max_len) for t in test_df['text']])\n",
    "y_test = torch.tensor(test_df['label'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e70a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "GLOVE_PATH = os.path.join(ROOT_PATH, 'data/raw/glove.6B/glove.6B.300d.txt')\n",
    "embedding_dim = 300\n",
    "pretrained_embeddings = load_glove_embeddings(GLOVE_PATH, word2idx, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model: 'cnn', 'bilstm', or 'bert'\n",
    "model_type = 'cnn'  # Change to 'bilstm' or 'bert' as needed\n",
    "\n",
    "if model_type == 'cnn':\n",
    "    model = SpamCNN(vocab_size=len(word2idx), embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings)\n",
    "    train_inputs, train_labels = X_train, y_train\n",
    "    test_inputs, test_labels = X_test, y_test\n",
    "elif model_type == 'bilstm':\n",
    "    model = BiLSTMSpam(vocab_size=len(word2idx), embedding_dim=embedding_dim, pretrained_embeddings=pretrained_embeddings)\n",
    "    train_inputs, train_labels = X_train, y_train\n",
    "    test_inputs, test_labels = X_test, y_test\n",
    "elif model_type == 'bert':\n",
    "    from transformers import BertTokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    def bert_encode(texts, tokenizer, max_len=200):\n",
    "        return tokenizer(texts.tolist(), padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')\n",
    "    train_encodings = bert_encode(train_df['text'], tokenizer, max_len)\n",
    "    test_encodings = bert_encode(test_df['text'], tokenizer, max_len)\n",
    "    model = SpamBERT()\n",
    "    train_inputs, train_labels = train_encodings, y_train\n",
    "    test_inputs, test_labels = test_encodings, y_test\n",
    "else:\n",
    "    raise ValueError('Invalid model_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "\n",
    "# Training Loop\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4)\n",
    "\n",
    "if model_type in ['cnn', 'bilstm']:\n",
    "    train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "    test_dataset = TensorDataset(test_inputs, test_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "else:  # BERT\n",
    "    train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
    "    test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        if model_type == 'bert':\n",
    "            input_ids, attention_mask, labels = [b.cuda() if torch.cuda.is_available() else b for b in batch]\n",
    "            outputs, _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        else:\n",
    "            inputs, labels = [b.cuda() if torch.cuda.is_available() else b for b in batch]\n",
    "            outputs = model(inputs)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model to Google Drive\n",
    "model_save_file = os.path.join(MODEL_SAVE_PATH, f'spam_{model_type}.pt')\n",
    "model.save(model_save_file)\n",
    "print(f\"Model saved to {model_save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647f947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
